import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tqdm import tqdm
import matplotlib.pyplot as plt

# --------------------------------------------------------------------------
# ğŸ“Œ 1. í™˜ê²½ ì„¤ì • ë° ì§€í‘œ ì •ì˜
# --------------------------------------------------------------------------
set_seed = lambda x: np.random.seed(x) or torch.manual_seed(x)
set_seed(42)

LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 32, 50
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ğŸ“Œ CSV íŒŒì¼ ê²½ë¡œ ì •ì˜
TRAIN_CSV = 'POS_train_val.csv'
TEST_CSV = 'POS_test.csv'

SALES_COL = 'ì¼ë§¤ì¶œ'
DATE_COL = 'ì˜ì—…ì¼ì'
GROUP_COL = 'ê·¸ë£¹í‚¤'

def smape(y_true, y_pred):
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    denominator[denominator == 0] = 1e-6
    return np.mean(numerator / denominator) * 100

# --- 2. LSTM ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (Sales Only) ---
class SimpleLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim=64, output_dim=7):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=3, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

# --- 3. ë°ì´í„° ë¡œë“œ ë° íŠ¹ì§• ìƒì„± í•¨ìˆ˜ (CSV íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ Train/Test ë¶„ë¦¬) ---
def create_data_for_lstm(train_csv, test_csv):
    try:
        df_train_raw = pd.read_csv(train_csv)
        df_test_raw = pd.read_csv(test_csv)
    except Exception as e:
        print(f"Error: File loading failed. {e}"); return pd.DataFrame(), pd.DataFrame(), []

    def clean_data(df):
        # ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
        df.rename(columns={DATE_COL: 'date', SALES_COL: 'sales'}, inplace=True)
        
        # ë‚ ì§œ ë° ìˆ«ì ì „ì²˜ë¦¬
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        
        def clean_sales(series):
            # ì‰¼í‘œ(,) ì œê±° ë° float ë³€í™˜
            series = series.astype(str).str.replace(',', '', regex=False)
            return pd.to_numeric(series, errors='coerce').fillna(0)
        
        df['sales'] = clean_sales(df['sales'])
        df[GROUP_COL] = 'ì „ì²´'
        return df.sort_values('date').fillna(0).reset_index(drop=True)

    df_train = clean_data(df_train_raw)
    df_test = clean_data(df_test_raw)
    
    meta_cols = []

    # df_trainê³¼ df_testë¥¼ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜
    return df_train, df_test, meta_cols

# --- 4. í›ˆë ¨, ì˜ˆì¸¡ ë° ê²€ì¦ í•¨ìˆ˜ ---
def train_predict_validate():
    # ğŸ“Œ ë³€ê²½: df_trainê³¼ df_testë¥¼ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¡œë“œ
    df_train, df_test, meta_cols = create_data_for_lstm(TRAIN_CSV, TEST_CSV)
    if df_train.empty or df_test.empty: return

    print(f"Train Data Period: {df_train['date'].min().date()} ~ {df_train['date'].max().date()} ({len(df_train)} rows)")
    print(f"Test Data Period: {df_test['date'].min().date()} ~ {df_test['date'].max().date()} ({len(df_test)} rows)")

    # Scaling (df_trainë§Œ ì‚¬ìš©)
    sales_scaler = MinMaxScaler()
    df_train['sales_scaled'] = sales_scaler.fit_transform(df_train[['sales']].values)

    # ì‹œí€€ìŠ¤ êµ¬ì„±
    X_train, y_train = [], []
    sales_vals = df_train['sales_scaled'].values

    for i in range(len(df_train) - LOOKBACK - PREDICT + 1):
        X_train.append(sales_vals[i:i+LOOKBACK])
        y_train.append(sales_vals[i+LOOKBACK:i+LOOKBACK+PREDICT])

    X_train = torch.tensor(np.array(X_train)).float().to(DEVICE).unsqueeze(-1) # (N, L, 1)
    y_train = torch.tensor(np.array(y_train)).float().to(DEVICE)

    model = SimpleLSTM(input_dim=1).to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    model.train()
    for epoch in tqdm(range(EPOCHS), desc="Training LSTM (Minimal)"):
        idx = torch.randperm(len(X_train))
        for i in range(0, len(X_train), BATCH_SIZE):
            batch_idx = idx[i:i+BATCH_SIZE]
            X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]
            output = model(X_batch)
            loss = criterion(output, y_batch)
            optimizer.zero_grad(); loss.backward(); optimizer.step()

    # --- ì˜ˆì¸¡ (Predicting) - ìˆœìˆ˜ ì¬ê·€ì  ì˜ˆì¸¡ (Pure Recursive Forecasting) ---
    model.eval()
    test_predictions = []

    # ğŸ“Œ 1. ì´ˆê¸° ì‹œí€€ìŠ¤ ì„¤ì •: í›ˆë ¨ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ LOOKBACKì¼ ì‹¤ì œ ê°’
    sales_full_scaled = sales_scaler.transform(df_train[['sales']].values)
    start_index = len(df_train) - LOOKBACK
    
    # current_sales_seq: ì˜ˆì¸¡ ê°’ìœ¼ë¡œ ê°±ì‹ ë  Sales ì‹œí€€ìŠ¤ (ì‹¤ì œ ê°’ìœ¼ë¡œ ì‹œì‘)
    current_sales_seq = sales_full_scaled[start_index :].squeeze().copy()

    # ğŸ“Œ 2. ì¬ê·€ì  ì˜ˆì¸¡ ë£¨í”„ ì‹œì‘ (len(df_test)ë§Œí¼ ì˜ˆì¸¡)
    for t in tqdm(range(len(df_test)), desc="Recursive Prediction"):
        
        # 3. ëª¨ë¸ ì…ë ¥ êµ¬ì„± (Sales Only): (1, LOOKBACK, 1)
        x_t = torch.tensor(current_sales_seq).float().to(DEVICE).unsqueeze(0).unsqueeze(-1) 

        with torch.no_grad():
            # ëª¨ë¸ì€ 7ì¼ì¹˜ ì˜ˆì¸¡ì„ í•˜ì§€ë§Œ, ì¬ê·€ì  ì˜ˆì¸¡ì„ ìœ„í•´ ì²« 1ì¼ì¹˜ë§Œ ì‚¬ìš©
            pred_scaled = model(x_t).cpu().numpy().squeeze()
            
        # 4. ì˜ˆì¸¡ ê°’ ì¶”ì¶œ ë° ì–‘ìˆ˜ ì²˜ë¦¬ (ë¯¸ë˜ ì •ë³´ ì‚¬ìš© ì œê±°)
        next_pred_scaled = pred_scaled[0] # ë‹¤ìŒ ë‚  ì˜ˆì¸¡ ê°’ (ìŠ¤ì¼€ì¼ë§ ë¨)
        
        # ìŠ¤ì¼€ì¼ë§ ë³µì›
        restored_val = sales_scaler.inverse_transform([[next_pred_scaled]])[0, 0]
        
        final_pred_val = max(0, restored_val) 

        test_predictions.append(final_pred_val)

        # 5. ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ (Recursive Step)
        # Sales ì‹œí€€ìŠ¤ ê°±ì‹ : ê°€ì¥ ì˜¤ë˜ëœ ê°’ ì œê±°, ëª¨ë¸ ì˜ˆì¸¡ ê°’(ìŠ¤ì¼€ì¼ë§ëœ) ì¶”ê°€
        current_sales_seq = np.roll(current_sales_seq, shift=-1)
        current_sales_seq[-1] = next_pred_scaled

    # --- ìµœì¢… ê²€ì¦ ë° ì‹œê°í™” ---
    y_true_test = df_test['sales'].values
    y_pred_test = np.array(test_predictions[:len(y_true_test)])

    test_mae = mean_absolute_error(y_true_test, y_pred_test)
    test_rmse = np.sqrt(mean_squared_error(y_true_test, y_pred_test))
    test_smape = smape(y_true_test, y_pred_test)

    print("\n" + "="*50)
    print("ğŸ“ˆ LSTM ì„±ëŠ¥ ê²€ì¦ (2. Sales Only - Pure Recursive)")
    print(f"Validation Period: {df_test['date'].min().date()} ~ {df_test['date'].max().date()}")
    print("="*50)
    print(f"1. MAE: {test_mae:,.2f} KRW")
    print(f"2. RMSE: {test_rmse:,.2f} KRW")
    print(f"3. SMAPE: {test_smape:.2f} %")
    print("="*50)

    # ì‹œê°í™” (ì˜ì–´ ë ˆì´ë¸” ì‚¬ìš©)
    df_results = pd.DataFrame({'Date': df_test['date'].values, 'Actual_Sales': y_true_test, 'LSTM_Prediction': y_pred_test})
    plt.figure(figsize=(16, 6))
    plt.plot(df_results['Date'], df_results['Actual_Sales'], label='Actual Daily Sales', color='blue')
    plt.plot(df_results['Date'], df_results['LSTM_Prediction'], label='LSTM Pure Recursive Prediction', color='red', linestyle='--')
    plt.title('2. LSTM Prediction (Sales Only - Pure Recursive) vs. Actual Daily Sales (No Future Info)', fontsize=18)
    plt.xlabel('Date'); plt.ylabel('Daily Sales (KRW)'); plt.legend(loc='upper right')
    plt.xticks(rotation=45, ha='right'); plt.tight_layout()
    plt.show()

if __name__ == '__main__':
    train_predict_validate()
